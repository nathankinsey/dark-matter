---
title: "Screening for candidate high impact variants with missing homozygosity"
author: "Nathan Kinsey"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(tidyverse)
library(data.table)
library(knitr)
library(rmarkdown)
```

# Data source and attribution

The data used for this analysis comes from the Dog Bio-medical Variant Database Consortium (DBVDC). This repository of whole genome sequenced data comes from over 120 different dog breeds, including some wolves. The variety of genomic data in the data set is further described in [a study by Jagannathan et. al. in 2019](https://doi.org/10.1111/age.12834). At the time of writing, there are 813 samples deposited for analysis. The file is stored in the conventional variant call format (VCF).

# Sweeping the whole genome for estimated high-impact, suspected highly-penetrant recessive lethal variants

## Data cleaning and pre-processing

The compressed VCF altogether is around 150GB and it was computationally prohibitive to run statistical software on the entire file. As a result, the file was divided by chromosome and software was run on a per-chromosome basis. This should have no affect on the downstream processing, as all quality control (QC) checks are done per variant. This was done under the assumption that all samples in the database are of high enough quality to consider. There were three samples that were removed from the data set, due to mix-up and contamination concerns, leaving 810 remaining.

```{bash preprocessing, eval=FALSE}
#!/bin/bash
#SBATCH --job-name=dmExtract    # Job name
#SBATCH --mail-type=ALL         # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mail-user=natkinsey@ucdavis.edu     # Where to send mail
#SBATCH --nodes=1                    # Run all processes on a single node	
#SBATCH --ntasks=1                   # Run a single task		
#SBATCH --cpus-per-task=6            # Number of CPU cores per task	
#SBATCH --mem=8gb                     # Job memory request
#SBATCH --time=12:00:00               # Time limit hrs:min:sec
#SBATCH --array=1-38
#SBATCH --output=slurm_out/dmExtract%A_%a.log   # Standard output and error log
pwd; hostname; date

rawdata="/share/oberbaurlab/LCG/Dog_Genome_Consortium/dogs.813.vars.flt.ann.vcf.gz"
datapath="/share/oberbaurlab/nk/DarkMatter/data"

# If working on chromosome 39, change all references to it to "X" for compatibility reasons
if [ $SLURM_ARRAY_TASK_ID = 39 ]; then
        SLURM_ARRAY_TASK_ID="X"
fi

# Extract a single chromosome and remove bad samples
cd ${datapath}/wgs
module load bcftools/1.10.2
bcftools index --threads 6 $rawdata
bcftools view -l 9 -O z -r ${SLURM_ARRAY_TASK_ID} -s ^LN47,BE020,ZS14 -o dbvdc810_${SLURM_ARRAY_TASK_ID}.vcf.gz --threads 6 $rawdata 
module unload bcftools/1.10.2

# Use Ensembl VEP to predict the effect of variants
cd /share/oberbaurlab/ensembl-vep
./vep -i ${datapath}/wgs/dbvdc810_${SLURM_ARRAY_TASK_ID}.vcf.gz -o ${datapath}/wgs/VEP_${SLURM_ARRAY_TASK_ID}.txt --sift b --offline --cache --dir ./cache_dir/ --fork 4 --buffer_size 10000 --no_stats --species canis_lupus_familiaris --tab --fields "Location,Allele,Gene,Consequence,IMPACT,SIFT"

# Generate HWE p-values and allele counts
module load plink2
plink2 --vcf ${datapath}/wgs/dbvdc810_${SLURM_ARRAY_TASK_ID}.vcf.gz --dog --const-fid --set-missing-var-ids @:# --maf 0.05 --max-maf 0.25 --hardy --out ${datapath}/wgs/dbvdc810_${SLURM_ARRAY_TASK_ID}
```

Ensembl VEP (Version 104) was used to predict the impact of variants found in the VCFs as well as generate SIFT scores to estimate how deleterious the missense mutations were. SIFT scores consider "sequence conservation and amino acid properties to predict whether an amino acid substitution is deleterious" [(Vaser et al., 2016)](https://doi.org/10.1038/nprot.2015.123).

Plink was run on all of the DBVDC WGS data to determine genotype frequency counts as well as Hardy-Weinberg equilibrium (HWE) exact test statistics. Plink 2 was notably used, as it is able to handle multiallelic variants, unlike its predecessor. QC parameters discarded variants with a minor allele frequency of 5% or less, as they were deemed too rare to prove insightful for this study. A maximum minor allele frequency of 17% was set, as that is a bit higher than the 15.2% maximum for recessive lethal previously reported in cattle [(Upperman et al., 2019)](https://doi.org/10.1186/s12711-019-0477-3). A maximum was deemed necessary to include, as not setting one highlighted regions with sequencing issues rather than true recessive lethal variants. A maximum carrier frequency of 25% was also set, as the maximum specified in the same paper was 23.4%.

## Identifying variants with high estimated impact on protein function

Two main reports from VEP were used to categorize variants as "high-impact." The "Impact" column is a subjective severity rating used to estimate how deleterious a variant might be. "High" impact variants were selected, [which includes](https://m.ensembl.org/info/genome/variation/prediction/predicted_data.html): transcript ablation, splice acceptor/donor, stop gained/lost, start lost, transcript amplification, and frameshift variants. Variants were also considered high-impact for the purpose of this screening if they had a SIFT score that predicted a missense mutation to be deleterious with high confidence.

```{r impact}
# Read annotation data from VEP and filter out lower-impact variants
highImpact <- tibble()
for (datafile in Sys.glob("../data/wgs/*.txt")) {
    vep <- fread(file = datafile, skip = "#Location", na.strings = "-") %>% 
        filter(IMPACT == "HIGH" | str_detect(SIFT, "deleterious\\(")) %>% 
        separate(col = "#Location", sep = ":", into = c("CHR", "BP"), convert = TRUE) %>% 
        distinct()
    
    highImpact <- bind_rows(highImpact, vep)
    rm(vep)
}

write_csv(highImpact, "../data/highImpact.csv")

numHighImpact <- nrow(highImpact)
```

The flagged variants were written to "highImpact.csv." A sample of the results are shown below:

```{r sample1}
kable(head(highImpact))
```

"CHR" denotes the chromosome the variant is on and "BP" specifies its base-pair coordinates. "Allele" refers to the specific genotype used for impact prediction. NA values imply a deletion. "Gene" refers to the Ensembl-stable gene ID and does not contain any common gene names. "Consequence" denotes the variant's likely effect on transcription or translation. "IMPACT" refers to the subjective categorization scheme discussed previously. "SIFT" denotes the aforementioned score for missense mutations.

## Identifying variants with suspected highly-penetrant recessive lethality

While the HWE test statistics highlight exceedingly unbalanced ratios of homozygosity and heterozygosity, they do not differentiate between cases in which the equilibrium is violated based on too many heterozygotes or homozygotes. As such, variants with minor alleles that have more than 2 homozygous cases in the data-set were discarded. 2 cases were allowed to account for some genotyping error. This means that all remaining variants with low HWE p-values must have unusually high heterozygosity and missing homozygosity. Such variants would imply recessive lethality.

Variants with HWE p-values greater than 0.05 were discarded. We correct for multiple testing using the Benjamini & Yekutieli (2001) method to control the false discovery rate.

```{r hwe}
# Read HWE exact test and genotype count data from Plink and filter for suspected recessive lethality
susLethal <- tibble()
numTotalVar <- 0

# Perform MAF and carrier frequency filtering, as PLINK did not do so successfully
calcMAF <- function(hom1, het, hom2) {
    freq1 <- (hom1 + het / 2) / sum(hom1, het, hom2)
    if (is.na(freq1)){
        return(999)
    } else if (freq1 <= 0.5) {
        return(freq1)
    } else {
        return(1 - freq1)
    }
}

calcCarrier <- function(hom1, het, hom2) {
    return(het / sum(hom1, het, hom2))
}

for (datafile in Sys.glob("../data/wgs/*.hardy")) {
    hardy <- fread(file = datafile) %>% 
        select(!c("#CHROM", "O(HET_A1)", "E(HET_A1)")) %>% 
        separate(col = ID, sep = ":", into = c("CHR", "BP"), convert = TRUE)
    
    numTotalVar <- numTotalVar + nrow(hardy)
    hardy <- filter(hardy, HOM_A1_CT <= 2 | TWO_AX_CT <=2) %>% 
        rowwise() %>%
        mutate(MAF = calcMAF(`HOM_A1_CT`, `HET_A1_CT`, `TWO_AX_CT`)) %>% 
        mutate(carryF = calcCarrier(`HOM_A1_CT`, `HET_A1_CT`, `TWO_AX_CT`)) %>%
        ungroup() %>% 
        filter(MAF <= 0.17 & carryF <= 0.25 & MAF >= 0.05)
    
    susLethal <- bind_rows(susLethal, hardy)
    rm(hardy)
}

susLethal <- mutate(susLethal, P = p.adjust(P, method = "BY")) %>% 
    filter(P < 0.05)
write_csv(susLethal, "../data/susLethal.csv")

numLethal <- nrow(susLethal)
```

The suspected lethal variants were written to "susLethal.csv." "CHR" denotes the chromosome the variant is on and "BP" specifies its base-pair coordinates. "A1" and "AX" denote the reference and alternate alleles respectively. "HOM_A1_CT" counts the number of samples homozygous for the reference allele, "HET_A1_CT" counts the number heterozygous for the reference allele, and "TWO_AX_CT" counts the number with two alternate alleles (not necessarily homozygous at loci with more than two alleles). "P" specifies the BY-corrected P-values that the variant is in Hardy-Weinberg equilibrium. "MAF" and "carryF" are the minor allele frequency and carrier frequency, respectively.

## Cross-referencing identified variants to yield candidates for downstream validation

Variants that appeared in both the impact screening and the recessive lethal screening are labeled as candidates and will be reviewed further.

```{r crossReference}
# Merge the datasets to find high impact variants with missing homozygosity
## VEP marks all variant BP, while Plink only marks the first. Truncate to standardize
highImpact <- extract(highImpact, col = BP, into = "BP", regex = "(^[0-9]+)", convert = TRUE) %>% 
    select(CHR, BP, Gene, Consequence) %>% 
    distinct()

candidates <- inner_join(highImpact, susLethal, by = c("CHR", "BP"))
write_csv(candidates, "../data/candidates.csv")
numCandidates <- nrow(candidates)
numGenes <- length(unique(candidates$Gene))
```

The candidates were written to "candidates.csv." A sample of the results are shown below:

```{r sample2}
kable(head(candidates))
```

"CHR" denotes the chromosome the variant is on and "BP" specifies its base-pair coordinates. "Gene" refers to the Ensembl-stable gene ID and does not contain any common gene names. "Consequence" denotes the variant's likely effect on transcription or translation. "A1" and "AX" refer to the two alleles that were counted and used for HWE test statistics. "HOM_A1_CT," "HET_A1_CT," and "TWO_AX_CT" specify the genotype counts for homozygous first allele, heterozygous, and homozygous second allele cases, respectively. "P" is the BY-corrected p-value for the Hardy-Weinberg exact test with that variant. "MAF" and "carryF" are the minor allele frequency and carrier frequency, respectively.

## Identifying candidate genes implicated by the screened variants

In the entire DBVDC data-set, there were `r numTotalVar` chromosomal variants. `r numHighImpact` of these variants were identified as high-impact. `r numLethal` were flagged as suspected recessive lethal. After both of these filtering steps, `r numCandidates` candidate variants remained. These variants implicated `r numGenes` candidate genes, listed below.

```{r genes}
paged_table(distinct(select(candidates, CHR, Gene)))
```

# System information

PLINK v2.00a3LM 64-bit Intel (20 Oct 2020) was used to generate HWE test statistics and allele counts.
Ensembl VEP version 104 was used for annotation and impact prediction, using CanFam3.1.

```{r sysInfo}
sessionInfo()
```
